{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7367c398-ebef-4368-bdd4-95dfcdc97e67",
   "metadata": {},
   "source": [
    "# 0. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5826699-2d07-4493-824f-754f1198f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing and model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "\n",
    "# Pipeline utilities\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c80f3-1717-4d6f-928b-eed5c0de579b",
   "metadata": {},
   "source": [
    "# 1. Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5f2ab4-1a30-421d-a4e8-eea370234cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>8/14/13</td>\n",
       "      <td>Male</td>\n",
       "      <td>4/18/47</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>8/14/13</td>\n",
       "      <td>7/7/14</td>\n",
       "      <td>7/14/14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>1/27/13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1/22/82</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>1/27/13</td>\n",
       "      <td>1/26/13</td>\n",
       "      <td>2/5/13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>Male</td>\n",
       "      <td>5/14/91</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>4/14/13</td>\n",
       "      <td>6/16/13</td>\n",
       "      <td>6/16/13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>1/13/13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1/21/93</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1/13/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>3/26/13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1/22/73</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>3/26/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                name   first         last compas_screening_date   sex  \\\n",
       "0   1    miguel hernandez  miguel    hernandez               8/14/13  Male   \n",
       "1   3         kevon dixon   kevon        dixon               1/27/13  Male   \n",
       "2   4            ed philo      ed        philo               4/14/13  Male   \n",
       "3   5         marcu brown   marcu        brown               1/13/13  Male   \n",
       "4   6  bouthy pierrelouis  bouthy  pierrelouis               3/26/13  Male   \n",
       "\n",
       "       dob  age          age_cat              race  ...  v_decile_score  \\\n",
       "0  4/18/47   69  Greater than 45             Other  ...               1   \n",
       "1  1/22/82   34          25 - 45  African-American  ...               1   \n",
       "2  5/14/91   24     Less than 25  African-American  ...               3   \n",
       "3  1/21/93   23     Less than 25  African-American  ...               6   \n",
       "4  1/22/73   43          25 - 45             Other  ...               1   \n",
       "\n",
       "   v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
       "0           Low           8/14/13      7/7/14      7/14/14               0   \n",
       "1           Low           1/27/13     1/26/13       2/5/13               0   \n",
       "2           Low           4/14/13     6/16/13      6/16/13               4   \n",
       "3        Medium           1/13/13         NaN          NaN               1   \n",
       "4           Low           3/26/13         NaN          NaN               2   \n",
       "\n",
       "  start   end event two_year_recid  \n",
       "0     0   327     0              0  \n",
       "1     9   159     1              1  \n",
       "2     0    63     0              1  \n",
       "3     0  1174     0              0  \n",
       "4     0  1102     0              0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/compas-scores-two-years.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dec7fa-98ec-43c7-aab2-c01e20c8de87",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c307459-6f8f-419a-9182-39a265a69c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find duplicated columns\n",
    "def find_duplicated_columns(df):\n",
    "    duplicated_columns = []\n",
    "    for i in range(len(df.columns)):\n",
    "        for j in range(i+1, len(df.columns)):\n",
    "            if df.iloc[:,i].equals(df.iloc[:,j]):\n",
    "                duplicated_columns.append((df.columns[i], df.columns[j]))\n",
    "    return duplicated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9444dd-a397-4e8d-b2ed-d304b7cb64f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('compas_screening_date', 'screening_date'),\n",
       " ('compas_screening_date', 'v_screening_date'),\n",
       " ('decile_score', 'decile_score.1'),\n",
       " ('priors_count', 'priors_count.1'),\n",
       " ('screening_date', 'v_screening_date')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicated columns in the dataset\n",
    "duplicated_columns = find_duplicated_columns(df)\n",
    "duplicated_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab3ac5de-e664-4f66-b981-d1d37cde8835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/1514731654.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['c_jail_in'] = pd.to_datetime(df['c_jail_in']).dt.date\n",
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/1514731654.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['c_jail_out'] = pd.to_datetime(df['c_jail_out']).dt.date\n"
     ]
    }
   ],
   "source": [
    "# Merge the deplicated columns\n",
    "df['screening_date'] = df['compas_screening_date'] \n",
    "df['decile_score'] = df['decile_score'] \n",
    "df['priors_count'] = df['priors_count'] \n",
    "\n",
    "# Excluding time components in c_jail_in and c_jail_out\n",
    "df['c_jail_in'] = pd.to_datetime(df['c_jail_in']).dt.date\n",
    "df['c_jail_out'] = pd.to_datetime(df['c_jail_out']).dt.date\n",
    "\n",
    "# Drop some irrelevant columns\n",
    "data_drop = df.drop(columns=['compas_screening_date', \n",
    "                               'v_screening_date', \n",
    "                               'decile_score.1', \n",
    "                               'priors_count.1', \n",
    "                               'violent_recid', \n",
    "                               'type_of_assessment', \n",
    "                               'v_type_of_assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3981c17c-b6ab-44ff-bc47-8b207ef1e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "data_drop.to_csv('../data/data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d3b40-f4eb-4ebb-b253-a5173fdc198b",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "01194a9b-6709-4b70-832e-dec3d807080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition\n",
    "def partition(df, age_cat):\n",
    "    partitions = {}\n",
    "    unique_values = df[age_cat].unique() \n",
    "    for value in unique_values: \n",
    "        partitions[value] = df[df[age_cat] == value]\n",
    "    return partitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1b20c49a-694d-4299-aa38-a0424e14e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = '../data/data_cleaned.csv'\n",
    "df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "378ebc14-0214-4b80-aa4b-a9ae29e598a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less than 25 DataFrame Shape: (1529, 46)\n",
      "25 - 45 DataFrame Shape: (4109, 46)\n",
      "Greater than 45 DataFrame Shape: (1576, 46)\n"
     ]
    }
   ],
   "source": [
    "age_cat_partitions = partition(df, 'age_cat')\n",
    "less_than_25_df = age_cat_partitions.get('Less than 25', pd.DataFrame())\n",
    "twenty_five_to_45_df = age_cat_partitions.get('25 - 45', pd.DataFrame())\n",
    "greater_than_45_df = age_cat_partitions.get('Greater than 45', pd.DataFrame())\n",
    "\n",
    "print(\"Less than 25 DataFrame Shape:\", less_than_25_df.shape)\n",
    "print(\"25 - 45 DataFrame Shape:\", twenty_five_to_45_df.shape)\n",
    "print(\"Greater than 45 DataFrame Shape:\", greater_than_45_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "31b85c95-80fc-432f-83ed-72d3077e35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta Function\n",
    "def calculate_delta(partitions):\n",
    "    delta_results = {\n",
    "        'Less than 25': {'male': 0, 'female': 0},\n",
    "        '25 - 45': {'male': 0, 'female': 0},\n",
    "        'Greater than 45': {'male': 0, 'female': 0},\n",
    "    }\n",
    "    \n",
    "    for age_cat, df_partition in partitions.items():\n",
    "        # Calculate the probabilities\n",
    "        P_plus_male = df_partition[df_partition['sex'] == 'Male']['two_year_recid'].mean() # calculate P(+|e_i, gender)\n",
    "        P_plus_female = df_partition[df_partition['sex'] == 'Female']['two_year_recid'].mean()\n",
    "        \n",
    "        # Assuming the number of people of each gender in each partition as G_i\n",
    "        G_male = len(df_partition[df_partition['sex'] == 'Male'])\n",
    "        G_female = len(df_partition[df_partition['sex'] == 'Female'])\n",
    "        \n",
    "        # Calculate delta using the formula provided\n",
    "        delta_male = G_male * abs((P_plus_male - P_plus_female) / 2) # G_male\n",
    "        delta_female = G_female * abs((P_plus_female - P_plus_male) / 2) # G_female\n",
    "        \n",
    "        delta_results[age_cat]['male'] = delta_male\n",
    "        delta_results[age_cat]['female'] = delta_female\n",
    "    \n",
    "    return delta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "41fec98d-db15-4a2a-af81-2bdd2bcb4d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Category: Less than 25\n",
      "  Delta Male: 132.03993055555554\n",
      "  Delta Female: 30.642626913779207\n",
      "\n",
      "Age Category: 25 - 45\n",
      "  Delta Male: 145.10346964064436\n",
      "  Delta Female: 35.46290127195639\n",
      "\n",
      "Age Category: Greater than 45\n",
      "  Delta Male: 62.50666666666667\n",
      "  Delta Female: 14.695924764890282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_results = calculate_delta(age_cat_partitions)\n",
    "\n",
    "# Print the delta values to check them\n",
    "for age_cat, deltas in delta_results.items():\n",
    "    print(f\"Age Category: {age_cat}\")\n",
    "    print(f\"  Delta Male: {deltas['male']}\")\n",
    "    print(f\"  Delta Female: {deltas['female']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7234f9ef-ab8a-43d6-9de6-ffa1d99228b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Less than 25': {'male': 132.03993055555554, 'female': 30.642626913779207},\n",
       " '25 - 45': {'male': 145.10346964064436, 'female': 35.46290127195639},\n",
       " 'Greater than 45': {'male': 62.50666666666667, 'female': 14.695924764890282}}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982df7e-e3b8-4b4f-bfe6-72e27bf4a2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e4f32b-44c9-4541-af8c-80b67033b554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221e802-8d37-4f5a-a888-196710db3ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1565359c-5ba3-496c-ab69-5eac7c586a5b",
   "metadata": {},
   "source": [
    "## Algo 1: Local Massaging:\n",
    "less than 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5f3c4a04-6e09-4cc8-9146-b51fa1de3381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2972054888.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  less_than_25_df[col] = less_than_25_df[col].astype('category')\n",
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2972054888.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  less_than_25_df[col] = less_than_25_df[col].astype('category')\n",
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2972054888.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  less_than_25_df[col] = less_than_25_df[col].astype('category')\n",
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2972054888.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  less_than_25_df[col] = less_than_25_df[col].astype('category')\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X_columns = [\n",
    "    'race', 'juv_fel_count', 'decile_score', 'juv_misd_count', 'juv_other_count',\n",
    "    'priors_count', 'days_b_screening_arrest', 'c_days_from_compas', 'c_charge_degree',\n",
    "    'is_recid', 'r_days_from_arrest', 'is_violent_recid', 'score_text', 'v_decile_score',\n",
    "    'v_score_text', 'start', 'end', 'event' #, 'two_year_recid'\n",
    "]\n",
    "\n",
    "y_column = ['two_year_recid']\n",
    "\n",
    "# Get partition X and y\n",
    "less_than_25_X_1 = less_than_25_df[columns_to_select]\n",
    "less_than_25_y_1 = less_than_25_df[y_column]\n",
    "\n",
    "\n",
    "# Get delta\n",
    "delta_male_1 = delta_results['Less than 25']['male']\n",
    "delta_female_1 = delta_results['Less than 25']['female']\n",
    "\n",
    "\n",
    "\n",
    "# 1. H1: Build ranker (logistic regrewssion)\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming less_than_25_df is your DataFrame containing the features and target variable\n",
    "\n",
    "# Convert text columns to category\n",
    "for col in X_columns:\n",
    "    if less_than_25_df[col].dtype == 'object':\n",
    "        less_than_25_df[col] = less_than_25_df[col].astype('category')\n",
    "\n",
    "# Prepare X and y\n",
    "X = less_than_25_df[X_columns]\n",
    "y = less_than_25_df[y_column].values.ravel()  # Ensure y is in the correct shape\n",
    "\n",
    "# Since we're using categories, tell XGBoost to treat these columns as categorical\n",
    "categorical_columns = [X.columns.get_loc(c) for c in X.select_dtypes(['category']).columns]\n",
    "dtrain = xgb.DMatrix(X, label=y, enable_categorical=True, feature_names=X_columns, feature_types='c')\n",
    "\n",
    "# Specify parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Objective for binary classification\n",
    "    'eval_metric': 'logloss',  # Evaluation metric\n",
    "    'learning_rate': 0.1,  # Learning rate\n",
    "    'max_depth': 6,  # Depth of the trees\n",
    "    'min_child_weight': 1,  # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.8,  # Subsample ratio of columns when constructing each tree\n",
    "    # 'n_estimators': 100,  # Number of trees\n",
    "}\n",
    "\n",
    "# Training the model\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predicting probabilities for y\n",
    "less_than_25_y_hat_1 = bst.predict(dtrain)\n",
    "\n",
    "less_than_25_y_hat_1 = pd.DataFrame(less_than_25_y_hat_1, columns=['two_year_recid_prob'])\n",
    "less_than_25_y_hat_1 = less_than_25_y_hat_1.set_index(less_than_25_y_1.index)\n",
    "\n",
    "# Join all tables\n",
    "less_than_25_df = pd.concat([less_than_25_X_1, less_than_25_y_1, less_than_25_y_hat_1], axis=1)\n",
    "\n",
    "# Add sex back for future category\n",
    "less_than_25_df = less_than_25_df.join(df['sex'], how='left')\n",
    "\n",
    "\n",
    "# Female\n",
    "num_rows = int(round(delta_female_1, 0))\n",
    "\n",
    "# Get the indices of the rows that meet your conditions and you want to update\n",
    "indices_to_update = less_than_25_df[(less_than_25_df['sex'] == 'Female') & (less_than_25_df['two_year_recid'] == 0)].sort_values(by='two_year_recid_prob', ascending=False).head(num_rows).index\n",
    "\n",
    "# Use loc to update the 'two_year_recid' values of those indices in the original DataFrame\n",
    "less_than_25_df.loc[indices_to_update, 'two_year_recid'] = 1\n",
    "\n",
    "# Male\n",
    "num_rows = int(round(delta_male_1, 0))\n",
    "\n",
    "# Get the indices of the rows that meet your conditions and you want to update\n",
    "indices_to_update = less_than_25_df[(less_than_25_df['sex'] == 'Male') & (less_than_25_df['two_year_recid'] == 1)].sort_values(by='two_year_recid_prob', ascending=True).head(num_rows).index\n",
    "\n",
    "# Use loc to update the 'two_year_recid' values of those indices in the original DataFrame\n",
    "less_than_25_df.loc[indices_to_update, 'two_year_recid'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "79ebcc83-b8e3-4e3c-a9de-7d542f96b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2251269887.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twenty_five_to_45_df[col] = twenty_five_to_45_df[col].astype('category')\n",
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2251269887.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twenty_five_to_45_df[col] = twenty_five_to_45_df[col].astype('category')\n",
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2251269887.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twenty_five_to_45_df[col] = twenty_five_to_45_df[col].astype('category')\n",
      "/var/folders/yd/0rx8hpn96fd0480f9ndhwn_00000gn/T/ipykernel_47433/2251269887.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twenty_five_to_45_df[col] = twenty_five_to_45_df[col].astype('category')\n"
     ]
    }
   ],
   "source": [
    "# 25-45\n",
    "\n",
    "# Get partition X and y\n",
    "less_than_25_X_1 = twenty_five_to_45_df[columns_to_select]\n",
    "less_than_25_y_1 = twenty_five_to_45_df[y_column]\n",
    "\n",
    "\n",
    "# Get delta\n",
    "delta_male_1 = delta_results['25 - 45']['male']\n",
    "delta_female_1 = delta_results['25 - 45']['female']\n",
    "\n",
    "\n",
    "\n",
    "# 1. H1: Build ranker (logistic regrewssion)\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "# Assuming less_than_25_df is your DataFrame containing the features and target variable\n",
    "\n",
    "# Convert text columns to category\n",
    "for col in X_columns:\n",
    "    if twenty_five_to_45_df[col].dtype == 'object':\n",
    "        twenty_five_to_45_df[col] = twenty_five_to_45_df[col].astype('category')\n",
    "\n",
    "# Prepare X and y\n",
    "X = twenty_five_to_45_df[X_columns]\n",
    "y = twenty_five_to_45_df[y_column].values.ravel()  # Ensure y is in the correct shape\n",
    "\n",
    "# Since we're using categories, tell XGBoost to treat these columns as categorical\n",
    "categorical_columns = [X.columns.get_loc(c) for c in X.select_dtypes(['category']).columns]\n",
    "dtrain = xgb.DMatrix(X, label=y, enable_categorical=True, feature_names=X_columns, feature_types='c')\n",
    "\n",
    "# Specify parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Objective for binary classification\n",
    "    'eval_metric': 'logloss',  # Evaluation metric\n",
    "    'learning_rate': 0.1,  # Learning rate\n",
    "    'max_depth': 6,  # Depth of the trees\n",
    "    'min_child_weight': 1,  # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'subsample': 0.8,  # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.8,  # Subsample ratio of columns when constructing each tree\n",
    "    # 'n_estimators': 100,  # Number of trees\n",
    "}\n",
    "\n",
    "# Training the model\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predicting probabilities for y\n",
    "less_than_25_y_hat_1 = bst.predict(dtrain)\n",
    "\n",
    "less_than_25_y_hat_1 = pd.DataFrame(less_than_25_y_hat_1, columns=['two_year_recid_prob'])\n",
    "less_than_25_y_hat_1 = less_than_25_y_hat_1.set_index(less_than_25_y_1.index)\n",
    "\n",
    "# Join all tables\n",
    "twenty_five_to_45_df = pd.concat([less_than_25_X_1, less_than_25_y_1, less_than_25_y_hat_1], axis=1)\n",
    "\n",
    "# Add sex back for future category\n",
    "twenty_five_to_45_df = twenty_five_to_45_df.join(df['sex'], how='left')\n",
    "\n",
    "\n",
    "# Female\n",
    "num_rows = int(round(delta_female_1, 0))\n",
    "\n",
    "# Get the indices of the rows that meet your conditions and you want to update\n",
    "indices_to_update = twenty_five_to_45_df[(twenty_five_to_45_df['sex'] == 'Female') & (twenty_five_to_45_df['two_year_recid'] == 0)].sort_values(by='two_year_recid_prob', ascending=False).head(num_rows).index\n",
    "\n",
    "# Use loc to update the 'two_year_recid' values of those indices in the original DataFrame\n",
    "twenty_five_to_45_df.loc[indices_to_update, 'two_year_recid'] = 1\n",
    "\n",
    "# Male\n",
    "num_rows = int(round(delta_male_1, 0))\n",
    "\n",
    "# Get the indices of the rows that meet your conditions and you want to update\n",
    "indices_to_update = twenty_five_to_45_df[(twenty_five_to_45_df['sex'] == 'Male') & (twenty_five_to_45_df['two_year_recid'] == 1)].sort_values(by='two_year_recid_prob', ascending=True).head(num_rows).index\n",
    "\n",
    "# Use loc to update the 'two_year_recid' values of those indices in the original DataFrame\n",
    "twenty_five_to_45_df.loc[indices_to_update, 'two_year_recid'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "da3edf4c-78e3-4e82-a907-022529a2c4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>r_days_from_arrest</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>score_text</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>two_year_recid_prob</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998814</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999537</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>173</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>5</td>\n",
       "      <td>825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4109 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  race  juv_fel_count  decile_score  juv_misd_count  \\\n",
       "1     African-American              0             3               0   \n",
       "4                Other              0             1               0   \n",
       "5                Other              0             1               0   \n",
       "6            Caucasian              0             6               0   \n",
       "7                Other              0             4               0   \n",
       "...                ...            ...           ...             ...   \n",
       "7202          Hispanic              0             2               0   \n",
       "7203          Hispanic              0             3               0   \n",
       "7204  African-American              0             4               0   \n",
       "7207  African-American              0             2               0   \n",
       "7212  African-American              0             2               0   \n",
       "\n",
       "      juv_other_count  priors_count  days_b_screening_arrest  \\\n",
       "1                   0             0                     -1.0   \n",
       "4                   0             2                      NaN   \n",
       "5                   0             0                      0.0   \n",
       "6                   0            14                     -1.0   \n",
       "7                   0             3                     -1.0   \n",
       "...               ...           ...                      ...   \n",
       "7202                0             0                      0.0   \n",
       "7203                0             0                     -1.0   \n",
       "7204                0             2                     -1.0   \n",
       "7207                0             0                     -1.0   \n",
       "7212                0             3                     -1.0   \n",
       "\n",
       "      c_days_from_compas c_charge_degree  is_recid  r_days_from_arrest  \\\n",
       "1                    1.0               F         1                 NaN   \n",
       "4                   76.0               F         0                 NaN   \n",
       "5                    0.0               M         0                 NaN   \n",
       "6                    1.0               F         1                 0.0   \n",
       "7                    1.0               F         0                 NaN   \n",
       "...                  ...             ...       ...                 ...   \n",
       "7202                 0.0               F         0                 NaN   \n",
       "7203                 1.0               F         0                 NaN   \n",
       "7204                 1.0               M         0                 NaN   \n",
       "7207                 1.0               M         1                 1.0   \n",
       "7212                 1.0               M         0                 NaN   \n",
       "\n",
       "      is_violent_recid score_text  v_decile_score v_score_text  start   end  \\\n",
       "1                    1        Low               1          Low      9   159   \n",
       "4                    0        Low               1          Low      0  1102   \n",
       "5                    0        Low               1          Low      1   853   \n",
       "6                    0     Medium               2          Low      5    40   \n",
       "7                    0        Low               3          Low      0   265   \n",
       "...                ...        ...             ...          ...    ...   ...   \n",
       "7202                 0        Low               3          Low    173   322   \n",
       "7203                 0        Low               1          Low      0   887   \n",
       "7204                 0        Low               3          Low      5   825   \n",
       "7207                 0        Low               2          Low      0   529   \n",
       "7212                 0        Low               2          Low      0   754   \n",
       "\n",
       "      event  two_year_recid  two_year_recid_prob     sex  \n",
       "1         1               1             0.998814    Male  \n",
       "4         0               0             0.000487    Male  \n",
       "5         0               0             0.000256    Male  \n",
       "6         1               1             0.999537    Male  \n",
       "7         0               0             0.001361    Male  \n",
       "...     ...             ...                  ...     ...  \n",
       "7202      0               0             0.002238    Male  \n",
       "7203      0               0             0.000261    Male  \n",
       "7204      0               0             0.000331    Male  \n",
       "7207      1               1             0.993684    Male  \n",
       "7212      0               0             0.000316  Female  \n",
       "\n",
       "[4109 rows x 21 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# greater than 45\n",
    "\n",
    "# to be continued:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd9c74-437a-42c7-b0c8-a89d5c61cf74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f22266-ecfc-4a0c-a0ea-e7c90d10bf5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f5f5f-9632-485a-994c-2888dd17f3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff16523-a491-4530-8bfd-12097b9c0a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44daa1a7-1be7-4876-aab3-d44bb86834c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85505328-4674-423e-96e6-17369c5497e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53235f45-97b3-419c-81b3-381759d52343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed5631-db3d-47ac-a10e-4b3afe450fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205fe4d-a74d-4766-8c4e-b330e5b149a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba52685-4fec-4fcf-9d23-5ad1e7c44ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f52668-aaba-48cd-98e1-2b80ec007f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba491363-cbc3-4834-a486-479173d7fd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa2862d1-529d-4d80-ab8d-76c22c535475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(file_path, features):\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Generate interaction features\n",
    "    data['race_x_priors_count'] = data['race'].astype(str) + '_' + data['priors_count'].astype(str)\n",
    "    data['sex_age_cat_interaction'] = data['sex'].astype(str) + \"_\" + data['age_cat'].astype(str)\n",
    "    data['race_decile_interaction'] = data['race'].astype(str) + \"_\" + data['decile_score'].astype(str)\n",
    "    data['charge_priors_interaction'] = data['c_charge_degree'].astype(str) + \"_\" + data['priors_count'].astype(str)\n",
    "    data['sex_race_interaction'] = data['sex'].astype(str) + \"_\" + data['race'].astype(str)\n",
    "    data['age_priors_interaction'] = data['age_cat'].astype(str) + \"_\" + data['priors_count'].astype(str)\n",
    "    \n",
    "    # Update features list to include the new interaction features\n",
    "    interaction_features = [\n",
    "        'race_x_priors_count', 'sex_age_cat_interaction', 'race_decile_interaction',\n",
    "        'charge_priors_interaction', 'sex_race_interaction', 'age_priors_interaction'\n",
    "    ]\n",
    "    all_features = features + interaction_features\n",
    "    \n",
    "    # Identify categorical and numerical features\n",
    "    categorical_features = [feature for feature in all_features if data[feature].dtype == 'O']\n",
    "    numerical_features = [feature for feature in all_features if feature not in categorical_features]\n",
    "    \n",
    "    # Preprocessing transformers\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Create preprocessing pipeline\n",
    "    preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    \n",
    "    # Apply preprocessing to the dataset with the features\n",
    "    data_processed = preprocessing_pipeline.fit_transform(data)\n",
    "    \n",
    "    # Get feature names after preprocessing\n",
    "    try:\n",
    "        categorical_features_names = preprocessing_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out()\n",
    "    except AttributeError:  # For older versions of sklearn\n",
    "        categorical_features_names = preprocessing_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names(categorical_features)\n",
    "    processed_feature_names = numerical_features + list(categorical_features_names)\n",
    "    \n",
    "    remainder_columns = [col for col in data.columns if col not in all_features]\n",
    "    feature_names = processed_feature_names + remainder_columns\n",
    "    \n",
    "    # Convert the numpy array returned by ColumnTransformer back to a dataframe\n",
    "    data_processed_df = pd.DataFrame(data_processed, columns=feature_names)\n",
    "    \n",
    "    for col in remainder_columns:\n",
    "        if data[col].dtype in ['int64', 'int32']:\n",
    "            data_processed_df[col] = data_processed_df[col].astype(data[col].dtype)\n",
    "    \n",
    "    data_processed_df.index = data.index\n",
    "    \n",
    "    return data_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f855e7ae-9954-4c43-8eeb-92604619f893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacksonzhao/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# File path and features list\n",
    "file_path = '../data/data_cleaned.csv'\n",
    "features = ['sex', 'race', 'age_cat', 'decile_score', 'v_decile_score', 'priors_count', 'c_charge_degree']\n",
    "\n",
    "# Process the dataset\n",
    "data_processed_df = preprocess_dataset(file_path, features)\n",
    "\n",
    "# Save the processed dataset to a new CSV file\n",
    "data_processed_df.to_csv('../data/featured_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c79a4-ca81-47fc-b449-7a354e2b4a5b",
   "metadata": {},
   "source": [
    "# 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cffbe0cf-9dd1-482e-9fb2-2394b16966d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacksonzhao/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/jacksonzhao/miniconda3/envs/5243_proj3/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Feature  Importance\n",
      "0                                      is_recid    0.830077\n",
      "1                             r_charge_desc_nan    0.076068\n",
      "2                                           end    0.009828\n",
      "3                         vr_charge_degree_(M1)    0.005974\n",
      "4                                         event    0.005766\n",
      "5                                  first_joshua    0.004266\n",
      "6        race_x_priors_count_African-American_8    0.003999\n",
      "7    race_decile_interaction_African-American_8    0.003773\n",
      "8    race_decile_interaction_African-American_2    0.003451\n",
      "9              age_priors_interaction_25 - 45_5    0.003176\n",
      "10                                        start    0.002898\n",
      "11                charge_priors_interaction_F_6    0.002755\n",
      "12                        r_charge_desc_Battery    0.002562\n",
      "13                charge_priors_interaction_M_2    0.002509\n",
      "14  c_charge_desc_Driving While License Revoked    0.002506\n",
      "15                charge_priors_interaction_F_3    0.002387\n",
      "16                            c_charge_degree_M    0.002375\n",
      "17                               race_Caucasian    0.001945\n",
      "18                        c_charge_desc_Battery    0.001706\n",
      "19                           r_days_from_arrest    0.001584\n"
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "def xgboost_feature_importance(file_path, target):\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Dynamically identify numeric and categorical features excluding the target\n",
    "    numeric_features = data.select_dtypes(include=['int64', 'float64']).columns.drop(target).tolist()\n",
    "    categorical_features = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Define preprocessing for numeric and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(sparse=True, handle_unknown='ignore'), categorical_features),\n",
    "        ])\n",
    "\n",
    "    # Splitting data into features (X) and target (y)\n",
    "    X = data.drop(columns=[target])\n",
    "    y = data[target]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Initialize and train the XGBoost classifier\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "\n",
    "    feature_names = numeric_features + \\\n",
    "                    preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()\n",
    "\n",
    "    # Extract feature importance\n",
    "    feature_importance = model.feature_importances_\n",
    "    \n",
    "    # Create a DataFrame for feature importances\n",
    "    importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "    importances_df = importances_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return importances_df\n",
    "\n",
    "# Example usage\n",
    "file_path = '../data/featured_data.csv'\n",
    "target = 'two_year_recid'\n",
    "feature_importance_df = xgboost_feature_importance(file_path, target)\n",
    "\n",
    "# Display the top 10 most important features\n",
    "print(feature_importance_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f594e5-0d47-4690-ac9e-a56e1ffab229",
   "metadata": {},
   "source": [
    "# 4. Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c031b7-e8d8-4c42-afb8-7c4c317f7700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da97d9-836a-48b4-b46c-d9569ac92933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602db0a8-5e7d-4bd7-b37d-f7aa5b391261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "559dcf8c-0bf1-4252-9ed5-adc80c5d7e2e",
   "metadata": {},
   "source": [
    "# 5. Fairness Intervention (Local Massaging and Preferential Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec76ee-dabf-45a0-a3fd-487fe78e25b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b5408-1b57-4a46-86fd-885fb05447aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b6cd5-0c6d-44c4-9000-c408ee31fc63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cb0f2-169b-4f84-b7a4-0aafb210de8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd3ed7-bcdc-4ce3-bc3e-8c140ed86f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f94a60-1786-4e3c-a17a-4b07697f6d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffaab90-2307-44bf-9b41-c03c7bf9dbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (5243_proj3)",
   "language": "python",
   "name": "5243_proj3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
